\documentclass{sig-alternate}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}
 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=6pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\begin{document}

\title{Melchior: A Compiler Assisted Deterministic System}

\numberofauthors{1}
\author{
\alignauthor
Yuzhong Wen\titlenote{}\\
       \affaddr{Virginia Tech}\\
       \email{wyz2014@vt.edu}
}


\maketitle
\begin{abstract}
The non-determinism execution order on multiprocessing system is a double-edge, while the maximum performance can be gained from this, the users and the developers are sometimes suffered from non-repeatable results for the same input. Especially for developers, debugging potential data races or threading related bugs in this case could be a disaster.

However with a deterministic system, it can be guaranteed that for a given input, a multi-threaded program is always executed in a same thread scheduling no matter how many times it runs. In this paper we present Melchior, a deterministic system that guarantees deterministic scheduling for a group of threads/processes. Melchior consists of a compiler part which instruments the program, a user-space utility to launch the deterministic namespace, and a patch to Linux kernel to control the scheduling inside the original Linux scheduler. The goal of Melchior is to control the sequence of inter-thread/process communication, in terms of thread synchronization, share memory access and system calls.

In this paper we also discussed the scalability of a deterministic system, and with Melchior's compiler support, we are able to mitigate this problem and achieve a relatively high scalability, the runtime overhead with big number of threads (up to 64) is much less than most existing deterministic systems. Among all the system level deterministic systems, Melchior is the fastest. We evaluated the implementation with a traditional parallel workload, pbzip2.

We also showed that Melchior can also be used on replicated execution, with our micro-benchmarks. In those evaluations, both the primary and the replica can always produce same results with a given input.

\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10010940.10010941.10010949.10010957.10010688</concept_id>
<concept_desc>Software and its engineering~Scheduling</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10010940.10010941.10010949.10010957.10010959</concept_id>
<concept_desc>Software and its engineering~Multiprocessing / multiprogramming / multitasking</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10010940.10010941.10010949.10010957.10010963</concept_id>
<concept_desc>Software and its engineering~Concurrency control</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10010940.10010941.10010949.10010957.10011678</concept_id>
<concept_desc>Software and its engineering~Process synchronization</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10011007.10011006.10011041.10011048</concept_id>
<concept_desc>Software and its engineering~Runbocchino2009paralleltime environments</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Scheduling}
\ccsdesc[500]{Software and its engineering~Multiprocessing / multiprogramming / multitasking}
\ccsdesc[500]{Software and its engineering~Concurrency control}
\ccsdesc[500]{Software and its engineering~Process synchronization}
\ccsdesc[500]{Software and its engineering~Runtime environments}
%
% End generated code
%

\keywords{Deterministic Multithreading; Multicore; Determinism}

\section{Introduction}
\subsection{Background}
The non-determinism execution order on a multi-core system is a double-edge, while the maximum performance can be gained from this, the users and the developers are sometimes suffered from non-repeatable results for the same input. This non-determinism comes from the parallel execution of different threads on different cores. Given the fact that each core's progress might be subject to change due to the OS scheduler, the time which each thread reaches the shared memory access would be different on every execution. While this non-determinism behaviour of multi-threaded programs is widely accepted by programmers, those developers are suffering from debugging those non-deterministic thread interleavings.

A workaround for debugging non-deterministic \\multi-threaded programs is via a record/replay system. A typical record/replay system runs the program in a specific runtime and logs the execution of the program, and during the replay phase, a debugger can replay the previous execution in a serial manner, which is easier to debug\cite{veeraraghavan2012doubleplay}. Also there're ways to replay the program in a parallel manner by only recording the schedule of the record run, so that on the replay run the program can be scheduled according to the previous schedule log\cite{cui2010stable}. However, an important fact is that the record run for a record/replay system is still not deterministic.

As a result, the need for a deterministic system still exists. Researchers from different fields are trying to tame the non-determinism in language level\cite{bocchino2009type}\cite{berger2009grace}\cite{leiserson2010cilk++}, runtime level\cite{aviram2012efficient}\cite{cui2013parrot}\cite{liu2011dthreads}\cite{bergan2010coredet}\cite{devietti2009dmp}\cite{olszewski2009kendo} even architectural level\cite{segulja2012architectural}. In fact, with determinism guaranteed, the programs' execution can be easily understood during the runtime, regardless different thread interleavings. It is also suggested that parallel programming should born to be deterministic\cite{bocchino2009parallel}.

\subsection{Melchior's Determinism}
For multi-threaded programs, an observation is that as long as the threads don't communicate, the execution is sure to be deterministic\cite{devietti2009dmp}. For example, in pthread based programs, all the inter-thread communications are synchronized by pthread primitives. By making the interleaving of sychronization primitives to be deterministic, the entire program is sure to be deterministic. With this observation, some runtime deterministic solutions actually enforce determinism by trapping pthread primitives\cite{cui2013parrot}\cite{liu2011dthreads}\cite{olszewski2009kendo}.

Melchior's runtime maintains a global execution order, according to this order, an execution token is passed among all the tasks deterministically. Only the task with the execution token can enter the deterministic area, and the token will be held on this task only if it leaves its deterministic area. In this way we have a more flexible deterministic solution for programmers to control the behaviour of their parallel programs. Unlike other runtime deterministic systems, Melchior's runtime does not directly trap pthread primitives, but provides two system calls for programmer to define a deterministic area. While Melchior's compiler framework can automatically instrument pthread primitives, a developer can also manually use those two system calls to handtune their applications. Figure ~\ref{fig:p1-1} shows the use of the system calls on a simple producer-consumer program. Line 5-7 and line 17-19 are two deterministic areas. Only the thread has the execution token can proceed at $syscall(\_\_NR\_det\_start)$, for other theads who also reach $syscall(\_\_NR\_det\_start)$, Melchior's runtime will put them into sleep until one of them has the token. In this case the order of executing pthread\_mutex\_lock is controlled by Melchior runtime in a deterministic way. As a result, putItem and getItem are also executed in a deterministic order since they are protected by a same mutex.

\begin{figure}
\centering
\begin{lstlisting}[frame=single,breaklines=true]
void producer() {
	while (running){
		item = generate_item();

		syscall(__NR_det_start);
		pthread_mutex_lock(mutex);
		syscall(__NR_det_end);
    
		putItem(queue, item);
    
		pthread_mutex_unlock(mutex);
	}
}

void consumer() {
	while (running){
		syscall(__NR_det_start);
		pthread_mutex_lock(mutex);
		syscall(__NR_det_end);
    
		item = getItem(queue);
    
		pthread_mutex_unlock(mutex);
		
		consume_item(item);
	}
}
\end{lstlisting}
\caption{An example use of Melchior's deterministic hints}
\label{fig:p1-1}
\end{figure}

\subsection{Related Work}
Deterministic systems have been studied for a long time. From the implementation perspective view, they can be categorized into 4 different genres: language level, runtime level, OS level and architectural level.

\subsection{Contribution}
This paper makes following contributions:

\begin{itemize}
  \item We present Melchior, a deterministic system with a runtime and a compiler framework that can make any pthread based program to run in a deterministic way transparently. Also supports fork based programs with manually annotation.
  \item We address the challenge of achieving high scalability in a deterministic system, and proposed a solution to mitigate the problem with our compiler framework.
  \item We evaluated Melchior's correctness with several micro-benchmarks, we show that with the same input, Melchior can always enforces the same output for those micro-benchmarks.
  \item We evaluated Melchior's performance with pbzip, where we achieve a relatively low overhead(fromit 17\% to 170\% for different number of threads), among all the deterministic systems that presented pbzip results, we are the 2nd fastest.
\end{itemize} 

\section{Deterministic Scheduling}
\subsection{Deterministic Logical Time}
Inspired by Kendo\cite{olszewski2009kendo} and Conversion\cite{merrifieldincreasing}, Melchior's maintains a "logical time" for each task inside the Melchior's runtime. Only the task holds the minimal logical time can have the token, if several tasks have the same logical time, the one who has the biggest PID number gets the token. As shown in Figure ~\ref{fig:p1-1}, the logical time increases by 1 when $syscall(\_\_NR\_det\_end)$ is called. Suppose the logical time for all the thread was 0 initially, after $syscall(\_\_NR\_det\_end)$ is called by a thread who has the token, its logical time will be 1. At this point the token will be released from this thread and will be handed over to another thread, the one who gets the token will be waken up from previous $syscall(\_\_NR\_det\_start)$ and proceeds to its deterministic area. In this algorithm, the logical time is increased deterministically, as a result, the token is passed in a deterministic way. We modelled a simple multi-producer-multi-consumer program along with this scheduling algorithm in TLA+. In the model,  consumers generate some output according to the item they get in parallel. With variants defined, we observed that the sequence of the consumers' output never changes. Which proves the correctness of this algorithm.

\subsection{Logical Time Imbalance}
However, after this algorithm simply was implemented, we found that the program's performance doesn't scale as the thread count increases, in other words, the scalability was very bad. The root cause is that we only increase the logical time by 1 at $syscall(\_\_NR\_det\_end)$. With an example we show how this could break the scalability and how to mitigate this problem.



\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography
\end{document}
